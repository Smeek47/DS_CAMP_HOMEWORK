{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "## Home Task \n",
    "\n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "### Load data \n",
    "\n",
    "</font>\n",
    "\n",
    "[Sentiment Analysis Dataset](https://www.kaggle.com/sonaam1234/sentimentdata)\n",
    "\n",
    "alternative source: \n",
    "<br>\n",
    "[rt-polaritydata](https://github.com/dennybritz/cnn-text-classification-tf/tree/master/data/rt-polaritydata)\n",
    "\n",
    "alternative source: \n",
    "<br>\n",
    "[Movie Review Data](http://www.cs.cornell.edu/people/pabo/movie-review-data)\n",
    "\n",
    "Each line in these two files corresponds to a single snippet (usually containing roughly one single sentence); all snippets are down-cased.  \n",
    "[More info about dataset](https://www.cs.cornell.edu/people/pabo/movie-review-data/rt-polaritydata.README.1.0.txt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_file(filename):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        content = f.read()\n",
    "    return content\n",
    "\n",
    "\n",
    "full_neg, full_pos = extract_text_from_file(\n",
    "    \"rt-polarity.neg\"), extract_text_from_file(\"rt-polarity.pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative words list len - 103030\n",
      "First ten elements - ['simplistic', 'silly', 'and', 'tedious', 'it', 's', 'so', 'laddish', 'and', 'juvenile']\n",
      "Positive words list len - 103204\n",
      "First ten elements - ['the', 'rock', 'is', 'destined', 'to', 'be', 'the', '21st', 'century', 's']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    return tokenizer.tokenize(text.lower())\n",
    "\n",
    "\n",
    "neg_text = preprocess(full_neg)\n",
    "pos_text = preprocess(full_pos)\n",
    "\n",
    "print(f\"Negative words list len - {len(neg_text)\n",
    "                                   }\\nFirst ten elements - {neg_text[:10]}\")\n",
    "print(f\"Positive words list len - {len(pos_text)\n",
    "                                   }\\nFirst ten elements - {(pos_text[:10])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All words list len - 206234\n",
      "First ten elements - ['simplistic', 'silly', 'and', 'tedious', 'it', 's', 'so', 'laddish', 'and', 'juvenile']\n"
     ]
    }
   ],
   "source": [
    "all_words = neg_text + pos_text\n",
    "print(f\"All words list len - {len(all_words)\n",
    "                              }\\nFirst ten elements - {all_words[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab len: 18359\n",
      "Ten the most common words - ('the', 'a', 'and', 'of', 'to', 's', 'it', 'is', 'in', 'that')\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "all_words = nltk.FreqDist(all_words)\n",
    "print(f\"Vocab len: {len(all_words)}\")\n",
    "\n",
    "\n",
    "most_common_words = list(zip(*all_words.most_common()))[0]\n",
    "print(f\"Ten the most common words - {most_common_words[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>binary_attitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the rock is destined to be the 21st century's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the gorgeously elaborate continuation of \" the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>effective but too-tepid biopic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>if you sometimes like to go to the movies to h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>emerges as something rare , an issue movie tha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  binary_attitude\n",
       "0  the rock is destined to be the 21st century's ...                1\n",
       "1  the gorgeously elaborate continuation of \" the...                1\n",
       "2                     effective but too-tepid biopic                1\n",
       "3  if you sometimes like to go to the movies to h...                1\n",
       "4  emerges as something rare , an issue movie tha...                1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_texts_with_cat = [[sentence, 1] for sentence in full_pos.splitlines()]\n",
    "neg_texts_with_cat = [[sentence, 0] for sentence in full_neg.splitlines()]\n",
    "\n",
    "all_texts = pos_texts_with_cat + neg_texts_with_cat\n",
    "\n",
    "df = pd.DataFrame(all_texts, columns=[\"text\", \"binary_attitude\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['text'], df['binary_attitude'], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features samples:\n",
      "['00' 'bv' 'discordant' 'genres' 'labour' 'overstylized' 'rotting'\n",
      " 'tackles' 'zest']\n",
      "\n",
      "len of features 16,021\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer().fit(X_train)\n",
    "print('features samples:\\n{}'.format(vect.get_feature_names_out()[::2000]))\n",
    "print('\\nlen of features {:,}'.format(len(vect.get_feature_names_out())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 178)\t1\n",
      "  (0, 930)\t2\n",
      "  (0, 1331)\t1\n",
      "  (0, 3396)\t1\n",
      "  (0, 5770)\t1\n",
      "  (0, 6529)\t1\n",
      "  (0, 6767)\t1\n",
      "  (0, 7407)\t1\n",
      "  (0, 7610)\t1\n",
      "  (0, 7622)\t1\n",
      "  (0, 8075)\t1\n",
      "  (0, 9738)\t1\n",
      "  (0, 12177)\t1\n",
      "  (0, 12681)\t1\n",
      "  (0, 15243)\t1\n",
      "  (0, 15595)\t1\n",
      "  (0, 15652)\t1\n"
     ]
    }
   ],
   "source": [
    "X_train_vectorized = vect.transform(X_train)\n",
    "print(X_train_vectorized[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1331</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5770</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6529</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6767</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7407</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7622</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8075</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12177</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12681</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15243</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15595</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15652</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       value\n",
       "178        1\n",
       "930        2\n",
       "1331       1\n",
       "3396       1\n",
       "5770       1\n",
       "6529       1\n",
       "6767       1\n",
       "7407       1\n",
       "7610       1\n",
       "7622       1\n",
       "8075       1\n",
       "9738       1\n",
       "12177      1\n",
       "12681      1\n",
       "15243      1\n",
       "15595      1\n",
       "15652      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X_train_vectorized[0].toarray(), index=[\"value\"]).T\n",
    "df[df[\"value\"] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[178, 930, 1331, 3396, 5770, 6529, 6767, 7407, 7610, 7622, 8075, 9738, 12177, 12681, 15243, 15595, 15652]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['about',\n",
       " 'as',\n",
       " 'been',\n",
       " 'cutting',\n",
       " 'fresh',\n",
       " 'have',\n",
       " 'hollywood',\n",
       " 'instead',\n",
       " 'is',\n",
       " 'issue',\n",
       " 'last',\n",
       " 'of',\n",
       " 'satire',\n",
       " 'should',\n",
       " 'variety',\n",
       " 'week',\n",
       " 'what']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(list(df[df[\"value\"] > 0].index))\n",
    "[vect.get_feature_names_out()[index]\n",
    " for index in df[df[\"value\"] > 0].index.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(max_iter=2000, C=2, solver=\"saga\").fit(\n",
    "    X_train_vectorized, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1: 0.7700374531835205\n",
      "AUC: 0.8437619827600285\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(vect.transform(X_test))\n",
    "print(f\"f1: {f1_score(y_test, predictions)}\")\n",
    "scores = clf.decision_function(vect.transform(X_test))\n",
    "print(f\"AUC: {roc_auc_score(y_test, scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest coefs:\n",
      "['dull' 'waste' 'boring' 'bore' 'neither' 'problem' 'worst'\n",
      " 'disappointment' 'suffers' 'supposed']\n",
      "\n",
      "Largest Coefs: \n",
      "['masterpiece' 'thanks' 'liberating' 'unflinching' 'enjoyable'\n",
      " 'entertaining' 'remarkable' 'glorious' 'engrossing' 'solid']\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "sorted_coef_index = clf.coef_[0].argsort()\n",
    "print(f\"Smallest coefs:\\n{feature_names[sorted_coef_index[:10]]}\\n\")\n",
    "print(f\"Largest Coefs: \\n{feature_names[sorted_coef_index[:-11:-1]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = green >\n",
    "\n",
    "## Learn more\n",
    "</font>\n",
    "\n",
    "sklearn.feature_extraction.text.CountVectorizer\n",
    "<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "Bag-of-words model\n",
    "<br>\n",
    "https://en.wikipedia.org/wiki/Bag-of-words_model\n",
    "\n",
    "tfâ€“idf\n",
    "<br>\n",
    "https://en.wikipedia.org/wiki/Tf%E2%80%93idf\n",
    "\n",
    "sklearn.feature_extraction.text.TfidfVectorizer\n",
    "<br>\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "\n",
    "Applied Text Mining in Python\n",
    "<br>\n",
    "https://www.coursera.org/learn/python-text-mining/home/welcome\n",
    "\n",
    "Natural Language Processing tutorial\n",
    "<br>\n",
    "https://pythonprogramming.net/tokenizing-words-sentences-nltk-tutorial/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<font color = green >\n",
    "\n",
    "## Next lesson: topic modeling \n",
    "</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
